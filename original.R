# -*- coding: utf-8 -*-
"""GIHPPA Assignment 2024S2 911277.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GsgpRshm8CzkdfcvIB-rsmmwsI4BHNpe
"""

##################### SETTING UP DATA FOR ANALYSIS #######################

dat <- read.csv("/content/freMTPL2freq.csv",header=TRUE)
# data preparations and corrections as used in Schelldorfer and
# Wüthrich (2019)
dat$VehGas <- factor(dat$VehGas)
dat$ClaimNb <- pmin(dat$ClaimNb,4)
dat$Exposure <- pmin(dat$Exposure,1)
# inspect data set
dim(dat) # count rows and colums
head(dat) # show first few policies
tail(dat) # show last few policies
#library(tidyverse) # work quietly to use %>% and make code tidy:
suppressMessages(library(tidyverse))
#Since car brand B12's new cars with regular fuel behave so special
# we create a new variable with a dummy brand "B12RN" (regular, new):
# "B12 regular, new car fleet"
dat$VehBrand2 <- as.factor(ifelse(dat$VehBrand=='B12' & dat$VehAge==0
                                  & dat$VehGas =='Regular', 'B12RN', as.character(dat$VehBrand)))

dat %>%
  group_by(VehBrand2) %>%
  summarise_at(vars(ClaimNb,Exposure), list(~sum(.), ~mean(.)))
# we perform the feature preprocessing according to Schelldorfer and
# Wüthrich (2019)
#- Area: we choose a continuous (log-linear) feature component for
# the Area code and we therefore map {A,...,F} → {1,...,6};
#- VehPower: we build 6 categorical classes by merging vehicle power
# groups bigger and equal to 9 (totally 6 labels);
#- VehAge: we build 3 categorical classes [0,1), [1,10], (10,∞);
#- DrivAge: we build 7 categorical classes [18,21), [21,26),
# [26,31), [31,41), [41,51), [51,71), [71, ∞);
#- BonusMalus: continuous log-linear feature component (we cap at
# value 150);
#- VehBrand: categorical feature component (totally 11 labels);
#- VehGas: binary feature component;
#- Density: log-density is chosen as continuous log-linear feature
# component;
#- Region: categorical feature component (totally 22 labels).
dat1 <- dat
dat1$AreaGLM <- as.integer(as.factor(dat1$Area))
dat1$VehPowerGLM <- as.factor(pmin(dat1$VehPower,9))
VehAgeGLM <- cbind(c(0:110), c(1, rep(2,10), rep(3,100)))
dat1$VehAgeGLM <- as.factor(VehAgeGLM[dat1$VehAge+1,2])
dat1[,"VehAgeGLM"] <-relevel(dat1[,"VehAgeGLM"], ref="2")
DrivAgeGLM <- cbind(c(18:100), c(rep(1,21-18), rep(2,26-21),
                                 rep(3,31-26), rep(4,41-31), rep(5,51-41), rep(6,71-51), rep(7,101-
                                                                                               71)))
dat1$DrivAgeGLM <- as.factor(DrivAgeGLM[dat1$DrivAge-17,2])
dat1[,"DrivAgeGLM"] <-relevel(dat1[,"DrivAgeGLM"], ref="5")
dat1$BonusMalusGLM <- as.integer(pmin(dat1$BonusMalus, 150))
dat1$DensityGLM <- as.numeric(log(dat1$Density))
dat1[,"Region"] <-relevel(factor(dat1[,"Region"]), ref="R24")
head(dat1) # show first few policies and generated features
# Modified function PDX: Weighted Poisson Deviance
PDW <- function(pred, obs, ex = rep(1, length(obs))) {
  200 * sum( ex * ( pred - obs + log((obs / pred) ^ (obs )))) /
    sum(ex)
}

PDW2 <- function(txt, l.c, l.x, l.e, t.c, t.x, t.e) {
  sprintf("%s, Learn/Test: %.2f%% / %.2f%%", txt, PDW(l.c, l.x,
                                                      l.e), PDW(t.c, t.x, t.e))
}
# Function CF2: Print claim frequency
CF2 <- function(txt, l.c, l.x, t.c, t.x) {
  sprintf("%s: %.2f%% / %.2f%%", txt, sum(l.c)/sum(l.x)*100,
          sum(t.c)/sum(t.x)*100)
}
# Function Benchmark.GLM2: Improvement in Poisson Deviance on test
# set compared to GLM2-INT-Improvement
Benchmark.GLM2 <- function(txt, pred) {
  index <- ((PDW(pred, test$ClaimNb, test$Exposure) -
               PDW(test$fit.cf, test$ClaimNb, test$Exposure)) / (PDW(test$fitGLM2,
                                                                     test$ClaimNb, test$Exposure) - PDW(test$fit.cf, test$ClaimNb,
                                                                                                        test$Exposure))) * 100
  sprintf("GLM2-Improvement-Index (PD test) of %s: %.1f%%", txt,
          index)
}
#In this case, the learning sample randomly takes 80% and the test
# sample 20% of the data sets.
# for later use (Ch.5) we create five 20%-subsamples ("folds") and
# take the last fold as the holdout data set
k <- 5
set.seed(42)
fold <- sample(1:k, nrow(dat1), replace = TRUE)
dat1$fold <- fold
learn <- dat1[dat1$fold != 5,] # 80%
test <- dat1[ dat1$fold == 5,] # 20%
CF2("Claim Frequency (Actual) Learn/Test",
    learn$ClaimNb,learn$Exposure, test$ClaimNb,test$Exposure)

####################### RUN INTERCEPT MODEL #######################

#The model "INT" consists solely of the intercept. It should give an
# impression of how much or little of the overall variation can be
# explained by classical and machine learning models.
# Model INT "predictions"
cf <- sum(learn$ClaimNb)/sum(learn$Exposure) # claim frequency
learn$fit.cf <- cf*learn$Exposure
test$fit.cf <- cf*test$Exposure
# Print Poisson Deviance (weighted)
PDW2("Poisson Deviance INT",
     learn$fit.cf,learn$ClaimNb,learn$Exposure,
     test$fit.cf,test$ClaimNb,test$Exposure)
# Print claim frequency actual vs predicted (Intercept model)
CF2("Claim Frequency INT, Test-Sample, Actual/Predicted",
    test$ClaimNb,test$Exposure, test$fit.cf,test$Exposure)

####################### RUN BASIC GLM #######################

t2 = proc.time()
f.glm2 <- ClaimNb ~ VehPowerGLM + VehAgeGLM + BonusMalusGLM +
  VehBrand + VehGas + DensityGLM + Region + AreaGLM + DrivAge +
  log(DrivAge) + I(DrivAge^2) + I(DrivAge^3) + I(DrivAge^4)
d.glm2 <- glm(f.glm2, data=learn, offset=log(Exposure),
              family=poisson())
summary(d.glm2) # print fit statistics and parameter list
# make predictions
learn$fitGLM2 <- fitted(d.glm2)
test$fitGLM2 <- predict(d.glm2, newdata=test, type="response")
dat$fitGLM2 <- predict(d.glm2, newdata=dat1, type="response") # for
# the CANN
proc.time() - t2

# Print claim frequency actual vs predicted
CF2("Claim Frequency GLM2, Test-Sample, Actual/Predicted",
    test$ClaimNb,test$Exposure, test$fitGLM2,test$Exposure)
# Print Poisson Deviance
PDW2("Poisson Deviance GLM2",
     learn$fitGLM2,learn$ClaimNb,learn$Exposure,
     test$fitGLM2,test$ClaimNb,test$Exposure)

####################### Run GLMs with regularisation (LASSO and Ridge Regression) #######################

#LASSO
# data preparation
install.packages("glmnet")
suppressMessages(library(glmnet))
f.lasso <- as.formula(ClaimNb ~ (VehPowerGLM + VehAgeGLM + DrivAgeGLM
                                 + BonusMalusGLM + VehBrand + VehGas + DensityGLM + Region +
                                   AreaGLM)^2)
f.lasso
x <- sparse.model.matrix(f.lasso, dat1)[, -1]
learn.glmnet <- x[dat1$fold != 5,] # 80%
test.glmnet <- x[dat1$fold == 5,] # 20%
# claim number and offset
fit.lasso <- cv.glmnet(x=learn.glmnet, y=learn$ClaimNb, offset =
                         log(learn$Exposure), alpha = 1, family = "poisson", nfolds = 5)
# Plot the regularization path
options(repr.plot.width=12, repr.plot.height = 9)

plot(fit.lasso,label = TRUE)
print(fit.lasso)
# Show non-zero coefficients
# Extract coefficients as a matrix and convert to a dataframe
df_lasso_coef <- as.data.frame(as.matrix(coef(fit.lasso, s = 0.01)))
#df_lasso_coef$variable <- rownames(df_lasso_coef)
# Filter out rows where coef is not equal to 0
(df_lasso_coef_filtered <- subset(df_lasso_coef, s1 != 0))
# cross-validation
{t1 <- proc.time()
  cv.lasso <- cv.glmnet(x = learn.glmnet, y=learn$ClaimNb, alpha =
                          1, offset = log(learn$Exposure), family = "poisson", nfolds = 5)
  (proc.time()-t1)}
plot(cv.lasso)
cv.lasso$lambda.min
# Show (a few) non-zero coefficients
df_lasso_coef <- as.data.frame(as.matrix(coef(cv.lasso, s =
                                                "lambda.min")))
df_lasso_coef_filtered <- subset(df_lasso_coef, s1 != 0)
dim(df_lasso_coef_filtered)
head(df_lasso_coef_filtered)
test$fitLASSO <- predict(cv.lasso, newx = test.glmnet, newoffset =
                           log(test$Exposure), type = "response", s = "lambda.min")[,1]
learn$fitLASSO <- predict(cv.lasso, newx = learn.glmnet, newoffset =
                            log(learn$Exposure), type = "response" , s = "lambda.min")[,1]
# Print claim frequency actual vs predicted
CF2('Claim Frequency LASSO, Test-Sample, Actual/Predicted',
    test$ClaimNb,test$Exposure, test$fitLASSO,test$Exposure)



#Ridge (Poisson) Regression
PDW2("Poisson Deviance LASSO",
     learn$fitLASSO,learn$ClaimNb,learn$Exposure,
     test$fitLASSO,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-
# Improvement
Benchmark.GLM2("LASSO", test$fitLASSO)
#Ridge (Poisson) Regression
{t1 <- proc.time()
  cvRIDGE <- cv.glmnet(x=learn.glmnet, y=learn$ClaimNb/learn$Exposure,
                       alpha = 0, weights = learn$Exposure, family = "poisson", nfolds = 5)
  (proc.time()-t1)}
plot(cvRIDGE)
cvRIDGE$lambda.min
test$fitRIDGE <- exp(predict(cvRIDGE, newx = test.glmnet, s =
                               "lambda.min"))[,1] * test$Exposure
learn$fitRIDGE <- exp(predict(cvRIDGE, newx = learn.glmnet, s =
                                "lambda.min"))[,1] * learn$Exposure
# Print claim frequency actual vs predicted
CF2('Claim Frequency RIDGE, Test-Sample, Actual/Predicted',
    test$ClaimNb,test$Exposure, test$fitRIDGE,test$Exposure)
# Print Poisson Deviance
PDW2("Poisson Deviance RIDGE",
     learn$fitRIDGE,learn$ClaimNb,learn$Exposure,
     test$fitRIDGE,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-
# Improvement
Benchmark.GLM2("RIDGE", test$fitRIDGE)

####################### Run the Generalised Additive Model (GAM) #######################

#GAM
suppressMessages(library(mgcv))
# bam(): Generalized additive models for very large datasets, see
# https://cran.r-project.org/web/packages/mgcv/mgcv.pdf
# "The advantage of bam is much lower memory footprint than gam, but it can also be much faster, for large datasets."
{t1 <- proc.time()
  d.gam3 <- bam(ClaimNb ~ s(VehAge) + s(DrivAge) + s(BonusMalusGLM) +
                  VehPowerGLM + VehGas + VehBrand + AreaGLM + DensityGLM + Region +
                  offset(log(Exposure)),
                ,data=learn, scale=-1, family=poisson)
  (proc.time()-t1)}
summary(d.gam3) # print fit statistics
# make predictions
learn$fitGAM3 <- fitted(d.gam3)
test$fitGAM3 <- predict(d.gam3, newdata=test, type="response")
# Print claim frequency actual vs predicted
CF2("Claim Frequency GLM2, Test-Sample, Actual/Predicted",
    test$ClaimNb,test$Exposure, test$fitGAM3,test$Exposure)
# Print Poisson Deviance
PDW2('Poisson Deviance GAM3',
     learn$fitGAM3,learn$ClaimNb,learn$Exposure,
     test$fitGAM3,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-Improvement
Benchmark.GLM2("GAM3", test$fitGAM3)
#Compare predictions between models
head(learn, n = 30)

####################### Run the Gradient Boosting models #######################

#XG Boost
#Data Preparation
num_features <-
  c('BonusMalus','DrivAge','VehPower','VehAge','Density')
cat_features <- c('Area','VehBrand','VehGas','Region')
features <- c(num_features, cat_features)
# Feature pre-processing for XGBoost and lightGBM
df_feat <- dat[,c(features)]
df_feat$Area <- as.integer(as.factor((df_feat$Area)))

print(paste("Features before one-hot-encoding:",dim(df_feat)[2]))
# one-hot encoding for Region and VehBrand
df_feat <- as.data.frame(model.matrix( ~ 0 +. ,data = df_feat))
print(paste("Features after one-hot-encoding: ",dim(df_feat)[2]))
# split data into learn and test
X_learn <- df_feat[dat1$fold != 5,] # 80%
X_test <- df_feat[dat1$fold == 5,] # 20%
# create monotonic constraints vector: increasing: +1, decreasing: - 1, unconstraint: 0
mtc <- c(rep( 0, length(X_learn)))
head(X_learn,2) # check feature names
mtc[1] <- 1 # BonusMalus increasing
print(mtc)
install.packages("xgboost")
suppressMessages(library(xgboost))
# construct xgb.DMatrices (these are the internal data structures
# used by XGBoost during training)
dtrain <- xgb.DMatrix(data = data.matrix(X_learn), label =
                        learn$ClaimNb/learn$Exposure, weight=learn$Exposure)
# make label wrong (shouldn't change anything): change to fold-number
dtest <- xgb.DMatrix(data = data.matrix(X_test), label =
                       test$fold/test$Exposure, weight=test$Exposure)
#XGBoost without constraints
# train model (using tuned hyperparameters, see corresponding Python notebook)
{t1 <- proc.time()
  fit.xgb0 <- xgb.train(data=dtrain, objective='count:poisson',
                        nrounds = 500, max_depth = 5, eta = 0.05,
                        tree_method = "hist")
  (proc.time()-t1)}
## make predictions
learn$fitXGB0 <- predict(fit.xgb0 , newdata = dtrain) *
  learn$Exposure
test$fitXGB0 <- predict(fit.xgb0, newdata = dtest) * test$Exposure
# Print claim frequency actual vs predicted
CF2('Claim Frequency XGB, Test-Sample, Actual/Predicted',
    test$ClaimNb,test$Exposure, test$fitXGB0,test$Exposure)
# Print Poisson Deviance
PDW2("Poisson Deviance XGB",
     learn$fitXGB0,learn$ClaimNb,learn$Exposure,
     test$fitXGB0,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-
# Improvement
test$fit.cf <- test$Exposure * sum(learn$ClaimNb)/sum(learn$Exposure)
# (recalculate INT-Model)
Benchmark.GLM2("XGB unconstraint", test$fitXGB0)
# XGBoost with monotonically increasing condition with BonusMalus to account for a tariff structure (as an example)
# train model (using tuned hyperparameters, see corresponding Python
# notebook)
{t1 <- proc.time()
  fit.xgb <- xgb.train(data=dtrain, objective='count:poisson',
                       monotone_constraints = mtc,
                       nrounds = 500, max_depth = 5, eta = 0.05,
                       tree_method = "hist")
  (proc.time()-t1)}
## make predictions
learn$fitXGB <- predict(fit.xgb , newdata = dtrain) * learn$Exposure
test$fitXGB <- predict(fit.xgb, newdata = dtest) * test$Exposure
# Print claim frequency actual vs predicted
CF2('Claim Frequency XGB, Test-Sample, Actual/Predicted',
    test$ClaimNb,test$Exposure, test$fitXGB,test$Exposure)
# Print Poisson Deviance
PDW2("Poisson Deviance XGB",
     learn$fitXGB,learn$ClaimNb,learn$Exposure,
     test$fitXGB,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-Improvement
test$fit.cf <- test$Exposure * sum(learn$ClaimNb)/sum(learn$Exposure)
# (recalculate INT-Model) Benchmark.GLM2("XGB", test$fitXGB)
#Light GBM is a fast and powerful gradient tree boosting machine
install.packages("R6", repos = "http://cran.r-project.org")
install.packages("lightgbm")
suppressMessages(library(lightgbm))
# LGB matrices (frequency-weighted-version)
# https://towardsdatascience.com/how-to-handle-the-exposure-offset-with-boosted-trees-fd09cc946837
llearn <- lgb.Dataset(data = data.matrix(X_learn), label =
                        learn$ClaimNb/learn$Exposure, weight=learn$Exposure)
ltest <- lgb.Dataset(data = data.matrix(X_test), label =
                       test$ClaimNb/test$Exposure, weight=test$Exposure)
params <- list(
  objective = "poisson"
  , metric = "poisson"
  , learning_rate = 0.1
  , monotone_constraints = mtc
  , num_leaves=31
  , n_estimators=100
)
# train lgb-model (using default hyperparameters, see corresponding Python notebook)
valids <- list(test = ltest)
{t2 <- proc.time()
  LGB <- lgb.train(
    params = params
    , data = llearn
    , valids = valids
  )
  (proc.time()-t2)}
## make predictions
learn$fitLGB <- predict(LGB, data.matrix(X_learn)) * learn$Exposure
test$fitLGB <- predict(LGB, data.matrix(X_test)) * test$Exposure
# Print claim frequency actual vs predicted
CF2('Claim Frequency lightGBM, Test-Sample, Actual/Predicted',
    test$ClaimNb,test$Exposure, test$fitLGB,test$Exposure)
# Print Poisson Deviance
PDW2("Poisson Deviance lightGBM",
     learn$fitLGB,learn$ClaimNb,learn$Exposure,
     test$fitLGB,test$ClaimNb,test$Exposure)
# Improvement in Poisson Deviance on test set compared to GLM2-INT-
# Improvement
test$fit.cf <- test$Exposure * sum(learn$ClaimNb)/sum(learn$Exposure)
# (recalculate INT-Model)
Benchmark.GLM2("LGB", test$fitLGB)

####################### Run the TreeSHAP code to explain light gbm predictions #######################
#This takes a while to run (>10minutes)
#Explaining lightGBMs predictions with TreeSHAP
#SHAP (SHapley Additive exPlanations) is an explainable AI method
# that helps interpret the output of any machine learning model. It
# fairly calculates the contribution of each feature to the final
# prediction. SHAP values range from negative to positive, with higher
# values indicating a greater impact on the outcome. It is based on the
# concept of Shapley values, a cooperative game theory that assigns a
# value to each player's contribution to a group's outcome. SHAP can be
# used to explain the model's decision for a single prediction instance
# or to provide a global overview of the model's behavior.
#For more information and an implementation in R, we recommend the
# tutorial "SHAP for Actuaries: Explain any Model" of M. Mayer, D.
# Meier, and M.V. Wüthrich (2023), https://github.com/actuarial-data-
# science/Tutorials/tree/master/14%20-%20SHAP.


# SHAP
install.packages(c("shapviz","kernelshap", "lightgbm"))
library(shapviz)
library(kernelshap)
# Generate explainer object with TreeSHAP to explain the LightGBM model
{t2 <- proc.time()
  shap_lgb_test <- shapviz(LGB, X_pred = data.matrix(X_test))
  (proc.time()-t2)}
#SHAP importance: summary plot
sv_importance(shap_lgb_test, kind = "bee")
# SHAP feature importance
sv_importance(shap_lgb_test, show_numbers = TRUE)
# SHAP dependence plots (note the different y-scales)
options(repr.plot.width=20, repr.plot.height = 15)
theme_set(theme_gray(base_size = 7))
sv_dependence(shap_lgb_test, colnames(X_test), jitter_width = 0.05,
              alpha = 0.2) &
  ylim(-0.8, 1.2)
options(repr.plot.width=12, repr.plot.height = 7)
head(test,4)
# Waterfall plot of first observation (log-scale)
sv_waterfall(shap_lgb_test, row_id = 1)
# Waterfall plot of sixth observation
sv_waterfall(shap_lgb_test, row_id = 6)
# Waterfall plot of seventh observation
sv_waterfall(shap_lgb_test, row_id = 7)
# Waterfall plot of eighth observation
sv_waterfall(shap_lgb_test, row_id = 8)

####################### #######################
head(learn, n = 30)[,c(1:20)]